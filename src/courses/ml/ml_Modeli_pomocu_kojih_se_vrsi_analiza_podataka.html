<h1>Модели помоћу којих се врши анализа података</h1>

<br>
Алгоритми машинског учења, иако тренутно веома развијени како теоријски тако и практично, и даље напредују и развијају се. У већини случајева, као што је већ речено, алгоритми који се користе у машинском учењу грубо се разврставају у три категорије: надгледано учење, ненадгледано учење и учење поткрепљивањем. У машинском учењу постоје две основне врсте проблема: регресија и класификација. <b>Регресија</b> представља проблем предвиђања непрекидне циљне променљиве. <b>Kласификација</b> је заправо разврставање односно груписање инстанци података у класе, односно предвиђање категоричке циљне вредности. 
<br>
<br>
Код надгледаног учења, скуп података укључује и жељене излазе (лабеле за задате инстанцеч скуп података називамо лабелираним) тако да функција може израчунати грешку за дато предвиђање која представља меру одступања од задатих лабела. Ово значи да у скупу података већ постоје информације којој класи дата инстанца припада (у случају класификације), или је позната нумеричка вредност циљног атрибута (у случају регресије). Када се изврши предвиђање, и добије грешка, модел се у односу на то може изменити ради бољих резултата. Већина модела машинског учења своје учење заснива на томе да покушава да минимизује вредност грешке, у идеалном случају да та грешка има вредност 0. 
<br>
<br>
Код ненадгледаног учења, скуп података не укључује жељени излаз. Уместо тога, модел покушава извести одређене закључке, односно уочити неку врсту структуре која је присутна на основу података који су на располагању. Другим речима, метод покушава да уочи неку зависност између атрибута односно особина датих инстанци, и да их на основу тога групише у класе са сличним особинама (у скучају кластеровања, односно груписања инстанци у кластере).
<br>
<br>
Учење поткрепљивањем користимо у ситуацијама када је пред нама проблем који је потребно решити предузимањем низа акција (као што је то у случају самовозећих аутомобила, када је потребно превести возило од тачке А до тачке Б предузимањем низа радњи – притискања гаса и кочнице, као и померањем волана). Потребно је научити модел, да у зависности од стања у коме се тренутно налази, као и од опаженог стања околине предузима краткорочне акције које воде ка испуњењу дугорочног циља (у зависности од брзине којом се креће, као и од стања на улици – број возила, временски услови, самовозећи аутомобил треба прилагодити своју брзину кретања). 
<br>
<br>
Даље ће бити дат кратак приказ кључних метода сваке од наведених категорија.
<br>
<br>


<h2>4.1 Модели надгледаног учења</h2>
<br>
Модели односно алгоритми који се најчешће користе у случају надгледаног учења могу се поделити у две основне категорије: регресија и класификација. Као што је малопре речено, код регресионих модела излаз (циљна променљива односно вредност која се предвиђа) је непрекидна променљива, док је код класификационих модела излаз дискретан. У случају класификације може постојати две или више класа.
<br>
<br>
<ol>
	<li><b>Линеарна регресија</b> (<i>Linear reggression</i>)
		<br>
		<br>
		<b>Линеарна регресија</b>  представља један од најједноставнијих и најчешће коришћених модела машинског учења. Она на једноставан начин проналази линеарну функцију која најбоље апроксимира податке. Линеарност се овде односи на линеарност по параметрима, тако да функција може бити и полиномијална. Пример графика линеарне регресије је приказан на слици:
		<br>
		<br>
		<img src="courses/ml/slike4/4.1.png" class="img-fluid img-md">
		<br>
		<br>
	</li>
	<li><b>Дрво одлучивања</b> (<i>Decision tree</i>)
		<br>
		<br>
		<b>Дрво одлучивања</b> представља може представљати како класификациони тако и регресиони модел надгледаног учења. Алгоритми овог типа стварају стабла која предвиђају резултат улазног вектора на основу правила одлучивања изведених из карактеристика присутних у подацима. Дрво одлучивања је користан модел у машинском учењу га је лако визуализовати, тако да је могуће разумети факторе који доводе до резултата. Једноставније речено, код овог модела је јасно на основу чега модел доноси закључке, што се може видети на слици испод. Изражена интерпретабилност једна је од значајнијих предности овог модела.
		<br>
		<br>
		<img src="courses/ml/slike4/4.2.png" class="img-fluid img-md">
		<br>
		<br>
		Дрво одлучивања је дијаграм налик структури у којој сваки унутрашњи чвор представља "тест" вредности појединачног атрибута, свака грана представља исход теста и сваки излазни чвор представља класу ознаке (одлука донета после рачунања свих атрибута). Стазе од корена до листа представљају правила класификације. У случају регресије, модификација је та што листови стабла не чувају категоричку, већ нумеричку вредност. 
		<br>
		<br>
	</li>
	<li><b>Неуронске мреже</b> (<i>Neural network</i>)
		<br>
		<br>
		<b>Неуронска мрежа</b> представља модел машинског учења који је биолошки инспирисан људским мозгом (везе између неурона, аксона, дендрита и начин функционисања људског мозга уопште покушава се пресликати у математичке моделе учења). Постоји већи број подврста неуронских мрежа од којих потпуно повезане неуронске мреже (<i>Feed-forward neural networks</i>) представљају најједноставнију варијанту. Модел потпуно повезане неуронске мреже састоји се од неурона који су организовани у слојеве, при чему су неурони из суседних слојева међусобно повезани. У случају већег броја слојева мрежа се назива дубоком, а унутрашнји слојеви скривеним слојевима. Илустрација изгледа дубоке неуронске мреже са једним скривеним слојем приказана је на слици. Метод обучавања оваквих модела назива се пропагација уназад, и састоји се од узастопног рачунања градијената (праваца најбржег раста функција). 
		<br>
		<br>
		<img src="courses/ml/slike4/4.3.png" class="img-fluid img-md">
		<br>
		<br>
	</li>
	<li><b>Логистичка регресија</b> (<i>Logistic regression</i>)
		<br>
		<br>
		<b>Логистичка регресија</b>, упркос имену, представља модел класификације. Она се користи за моделирање вероватноће коначног броја исхода, обично два. У суштини, логистичка регресија је креирана на такав начин да излазне вредности могу бити само између 0 и 1. У статистици се логистички модел користи за моделирање вероватноће одређене класе или догађаја који постоје, попут пролаза / неуспеха, победе / губитка, живог / мртвог или здравог / болесног.
		<br>
		<br>
		<img src="courses/ml/slike4/4.4.png" class="img-fluid img-md">
		<br>
		<br>
	</li>
	<li><b>Метода потпорних вектора</b> (<i>Support Vector Machine – SVM</i>)
		<br>
		<br>
		<b>Метода потпорних вектора</b> је модел надгледаног учења који може постати математички прилично компликован уколико се зађе у детање, али је прилично интуитиван  на најосновнијем нивоу. Претпоставимо да постоје две класе података. Ова метода ће наћи границу између две класе података односно хиперраван која на најбпљи могући начин раздваја податке који припадају различитим класама. Нови податак се класификује у зависности од тога са које стране хиперравни се налази. Другим речима, модел тежи да нађе хиперраван која најбоље раздваја инстанце две класе, односно која је на највећем могућем растојању од њих.
		<br>
	</li>
</ol>
<br>
Сви ови модели, али и неки додатни доступни су у окружењу <i>Orange</i>, у менију који се налази левој страни прозора, у делу под називом <i>Model</i>, који је приказан на слици испод.
<br>
<br>
<img src="courses/ml/slike4/4.5.png" class="img-fluid img-md">
<br>
<br>


<h2>4.1 Модели ненадгледаног учења</h2>
<br>
<ol>
	<li><b>Кластеровање</b> (<i>Clustering</i>)
		<br>
		<br>
		<b>Кластеровање</b> је техника ненадгледаног учења која подразумева груписање (кластеровање) тачака односно инстанци података. 
		<br>
		<br>
		Уобичајене технике кластеровaња су <b>кластеровање к-средина</b> (<i>K-means clustering</i>), <b>хијерархијско кластеровање</b> (<i>Hierarhical clustering</i>), и <b>кластеровање на основу густине</b> (<i>Density-based spatial clustering of applications with noise - DBSCAN</i>). Иако свака техника има различиту методу проналажења кластера, сви имају за циљ постићи исту ствар – груписање сличних инстанци у кластере то јест групе, што се може видети на слици.
		<br>
		<br>
		<img src="courses/ml/slike4/4.6.png" class="img-fluid img-md">
		<br>
		<br>
	</li>
	<li><b>Анализа главних компоненти</b> (<i>Principal Component Analysis PCA</i>)
		<br>
		<br>
		У најједноставнијем смислу oва метода подразумева да се подаци већих димензија (нпр. 3 димензије) сведу на мањи простор (нпр. 2 димензије). То резултира нижом димензијом података, који су аутоматски лакши за oбраду (рад са подацима великих димензија може бити проблематичан, како из рачунских тако и из разлога визуелизације и интуитивне представе подтака). На овај начин се мења и координатни систем, и сами атрибути. Ово је метода редукције димензионалности података и често се користи пре неког другог модела надгледаног учења. 
		<br>
		</li>
</ol>
<br>
Поменути модели, али и неки додатни доступни су у окружењу <i>Orange</i>, на левој страни прозора, у делу под називом <i>Unsupervised</i>, који је приказан на слици.
<br>
<br>
<img src="courses/ml/slike4/4.7.png" class="img-fluid img-md">
<br>
<br>
	



	
	
		
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
		


