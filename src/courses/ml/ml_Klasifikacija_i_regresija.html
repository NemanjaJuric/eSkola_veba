<h1>Класификација и регресија</h1>


<h2>7.1 Класификација </h2>
<br>
<br>
<b>Класификација</b> је тип проблема који се појављује у машинском учењу, где метод класификује податке у неку од група на основу сличности које је уочио.  Методи класификације  уче из података тренинг скупа, а затим користе научене зависности за класификацију нових инстанци.
<br>
<br>
Бинарни класификатори раде са само две класе односно два могућа исхода (на пример: позитиван или негативан одговор на неко питање; да ли пацијент има неку болест или не и слично). Постоје и вишекласни  класификатори који задате податке сврставају у више класа (на пример: којој земљи припада застава, да ли је на слици ружа, лала или орхидеја итд). У овом случају се  претпоставља да је сваки узорак додељен само једној класи. Постоје и варијације код којих једној инстанци припада више класа, али о њима неће бити речи. 
<br>
<br>
Неки практични примери проблема класификације су: препознавање говора, препознавање рукописа, препознавање лица, биометричка идентификација, класификација докумената, класификација тумора итд.
<br>
<br>
Постоји неколико врста метода за класификацију у машинском учењу, као што су:
<br>
<br>
<ul>
	<li>Логистичка регресија (<i>Logistic regression</i>)</li>
	<li>Наивни Бајесов класификатор (<i>Naive Bayes classifier</i>)</li>
	<li>Метод К најближих суседа (<i>kNN – K nearest neighbours</i>)</li>
	<li>Метод потпорних вектора (<i>SVM – Support vector machine</i>)</li>
	<li>Стабла одлучивања (<i>Decision tree</i>)</li>
	<li>Метод случајних шума (<i>Random forest</i>)</li>
	<li>Неуронске мреже (<i>Neural network</i>)</li>
</ul>
<br>
<br>
<b>Метод к-најближих суседа</b> (<i>К-Nearest Neighbor, КNN</i>) је често коришћен, јако интуитиван  метод машинског учења. Може се користити за класификацију са произвољним бројем класа. Ово је једноставан метод који чува све доступне инстанце при чему нове инстанце класификује на основу сличности са инстанцама из скупа за тренирање (на основу такозване функције удаљености). 
<br>
<br>
Метод памти све инстанце (у даљем тексту тачке) тренинг скупа заједно са њиховим лабелама. Да би класификовао нову тачку, он ће проћи кроз читав скуп тачака, у односу на задату меру удаљености пронаћи к најближих (то су најближи суседи), а затим на основу класе која се најчешће појављује класификовати нову инстацу. Употреба геометријске удаљености (нпр. еуклидско растојање) за дефинисање растојања међу тачкама не мора увек бити најповољније или чак могуће: врста уноса може, на пример, бити текст где на први поглед није јасно како треба мерити удаљеност. Стога метрику удаљености треба пажљиво бирати, за сваки проблем пoјединачно. У случају растојања међу текстуалним подацима може се користити такозвано косинусно растојање или метрике изведене из њега, али о томе неће бити речи на овом месту. 
<br>
<br>
Најбољи избор к зависи од података; генерално гледано, веће вредности к смањују непрецизности и грешке, али су зато границе међу класама мање јасне. Што се тиче окружења <i>Orange</i>, параметр к може се мењати у прозору који се појављује кликом на оператор <i>КNN</i>, у пољу <i>Number of neighbors</i>, што је приказано на слици. У овом прозору могуће је подешавати и метрику која ће се користити за мерење растојања међу инстанцама података. У овом примеру реч је о еукликдској метрици.
<br>
<br>
<img src="courses/ml/slike7/7.1.png" class="img-fluid img-sm">
<br>
<br>
Други популарни класификатор у машинском учењу је <b>логистичка регресија</b>. Логистичка регресија спада у методе класификације упркос свом називу. Ово је статистичка метода за анализу скупа података у којем постоји једна или више независних варијабли које одређују исход. Исход се мери дихотомном променљивом (у којој су само два могућа исхода). 
<br>
<br>
Ради илустрације ћемо посматрати скуп података <i>Iris</i>. Овај скуп најпре представимо табеларно, а затим одаберимо одговарајуће колоне на следећи начин:
<br>
<br>
<img src="courses/ml/slike7/7.2.png" class="img-fluid img-sm">
<br>
<br>
При повезивању оператора <i>Data Table</i> и <i>Select Columns</i> потребно је правилно повезати улазне и излазне податке:
<br>
<br>
<img src="courses/ml/slike7/7.3.png" class="img-fluid img-sm">

<br>
<br>
Даље, повезаћемо ове операторе са оператором <i>Test and Score</i> који се налази у одељку <i>Evaluate</i>. Овај оператор ће нам бити потребан ради евалуације и поређења модела које ћемо користити на нашем скупу података.
<br>
<br>
Оператор <i>Test and Score</i> повезаћемо са једне стране моделима к-најближих суседа (<i>kNN</i>) и логистичке регресије, а са друге стране операторима за евалуацију – матрицом конфузије, ROC кривом и лифт кривом, да бисмо користећи различите начине оцењивања проценили који је модел бољи за задати скуп података, као што је приказано на слици испод.
<br>
<br>
<img src="courses/ml/slike7/7.4.png" class="img-fluid img-md">
<br>
<br>
При повезивању оператора <i>Test and Score</i> са моделима за класификацију, опет је потребно водити рачуна о правилном повезивању података. Та веза мора бити одређена на следећи начин:
<br>
<br>
<img src="courses/ml/slike7/7.5.png" class="img-fluid img-sm">
<br>
<br>
Приказани прозор се појављује након клика на везу између жељених оператора.
<br>
<br>
Дакле, повезали смо скуп података са моделима класификације к-најближих суседа и логистичком регресијом, и доделили овим моделима команду да уче из података. Користећи три методе оцењивања, упоредићемо који је модел повољнији за учење на овом скупу података.
<br>
<br>
Податке о евалуацији добијамо двоструким кликом на оператор <i>Test and Score</i>:
<br>
<br>
<img src="courses/ml/slike7/7.6.png" class="img-fluid img-md">
<br>
<br>
На слици је приказана оцена ова два модела. У колони <i>CA (Classification Accurancy)</i> можемо видети тачност класификације, односно удео тачно класификованих инстанци за дат скуп података, за ове две методе на основу резултата сва три модела евалуације. Дакле, прецизност методе к-најближих суседа је 0.973 (97.3%), а прецизност методе логистичке регресије је 0.960 (96.0%). Додатно, метода најближих суседа на креираном скупу података поседује како већу прецизност, тако и већи одзив. Одавде можемо закључити да је за класификацију на скупу података Iris погодније користити методу к-најближих суседа.
<br>
<br>
Колона <i>AUC (Area Under Receiver Operating Characteristic)</i> је заправо површина испод ROC криве, о којој је више речи било у претходном поглављу, док је за остале метрике јасно на шта се односе. 
Искористићемо прилику да на овом примеру погледамо како изгледају посматране мере. Потребно је само кликнути на оператор који представља конкретан модел:
<br>
<br>
<ul>
	<li>Матрица конфузије:
	<br>
	<br>
	<img src="courses/ml/slike7/7.7.png" class="img-fluid img-md">
	<br>
	<br>
	</li>
	
	<li>ROC крива:
	<br>
	<br>
	<img src="courses/ml/slike7/7.8.png" class="img-fluid img-md">
	<br>
	<br>
	</li>
	
	<li>Лифт крива:
	<br>
	<br>
	<img src="courses/ml/slike7/7.9.png" class="img-fluid img-md">
	<br>
	<br>
	</li>
</ul>

	
<h2>7.2 Регресија</h2>
<br>
<br>
<b>Регресијa</b> је тип проблема се користи за предвиђање реалне вредности циљне променљиве. Један од најчешће коришћених и најједноставнијих примера регресије јесте предвиђање цене куће на основу неких карактеристика као што су њена локација, број соба и слично (скуп података под називом <i>Housing</i>).
<br>
<br>
Неке од важнијих врста регресијскионих метода у машинском учењу:
<br>
<br> 
<ul>
	<li>Линеарна регресија</li>
	<li>Метод к најближих суседа  (<i>kNN – K nearest neighbours</i>)</li>
	<li>Стабла одлучивања (<i>Decision tree</i>)</li>
	<li>Метод случајних шума (<i>Random forest</i>)</li>
	<li>Неуронске мреже (<i>Neural network</i>)</li>
</ul>
<br>
<br>
Важно је напоменути да се неки модели, попут неуронских мрежа или технике најближих суседа, уз мале модификације могу користити како за проблеме регресије тако и за проблеме класификације.
<br>
<br>
<b>Линеарна регресија</b> је метод машинског учења који припада моделима надгледаног учења. Најчешће се користи за откривање односа између променљивих и предвиђања. Линеарна регресија врши предвиђање вредности зависне променљиве Y на основу бредности једне или зише зависних променљивих X.  Дакле, ова метода машинског учења проналази линеарни однос који важи између улаза и излаза. Отуда име линеарна регресија.
<br>
<br>
Линеарна регресија је погодна за предвиђање резултата који је непрекидне вредности, као што је предвиђање цене некретнине. Његов резултат предвиђања може бити било који реалан број. 
<br>
<br>
Поставља се питање зашто линеарна регресија не може да се користи за решавање проблема класификације. Циљ линеарне регресије је да пронађе однос између улазних варијабли и циљне варијабле. Линеарна функција добијена из скупа за тестирање има за циљ да смањи удаљеност између предвиђене вредности и стварне вредности.
<br>
<br>
Најпре, проблем прави то што је код линеарне регресије предвиђена вредност континуирана, а не пробабилистичка (вероватносна). У проблему бинарне класификације оно што нас занима је вероватноћа да ће се исход догодити. Вероватноћа се креће између 0 и 1, где је вероватноћа да се нешто сигурно догоди 1, а 0 је нешто што се скоро сигурно неће догодити. У линеарној регресији предвиђени број може бити изван 0 и 1.
<br>
<br>
Додатно, као важно својство линеарне регресије на овом месту истичемо то да је линеарна регресија јако осетљива на одударајуће податке. Наиме, с обзиром да линеарна регресија конструише линеарну функцију минимизирањем грешке предвиђања, како би умањила удаљеност предвиђене и стварне вредности, сваки одударајући податак може направити велику разлику у предиђајућој функцији.  
<br>
<br>
Посматрајмо скуп података <i>Housing</i>. Овај скуп најпре представимо табеларно, као у претходном примеру. Даље, повезаћемо ове операторе са оператором <i>Test and Score</i> који се налази у одељку <i>Evaluate</i>.
<br>
<br>
Оператор <i>Test and Score</i> повезаћемо моделима к-најближих суседа (kNN) и линеарне регресије, као што је приказано на слици.
<br>
<br>
<img src="courses/ml/slike7/7.10.png" class="img-fluid img-md">
<br>
<br>
Кликом на оператор <i>Test and Score</i> можемо видети оцене ова два модела.
<br>
<br>
<img src="courses/ml/slike7/7.11.png" class="img-fluid img-md">
<br>
<br>
Колона <i>MSE (Mean square error)</i> је средњеквадратна грешка и заправо представља грешку средњеквадратног растојања тачака из скупа података од линеарне функције која је резултат линеарне регресије. Колона <i>RMSE (Root mean square error)</i> је корен средњеквадратне грешке, и као што је раније већ истакнуто користи се да би се анулирали квадрати који су присутни при израчунавању средњеквадратне грешке, и да би се ред величине грешке мерио на истој скали на којој се мери и циљна променљива. Ако је средњеквадратна грешка мала, то значи да добијена линеарна функција добро апроксимира скуп података. 
<br>
<br>
У овом случају, средњеквадратна грешка је мања код линеарне регресије, што значи да је овај модел повољнији за коришћење на скупу података <b>Housing</b>.
<br>
<br>
